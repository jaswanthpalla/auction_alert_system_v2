name: Daily Auction Scrape

on:
  schedule:
    - cron: '15 4 * * *'  # Runs daily at 10:00 AM IST (00:15 UTC)
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run-scrapers:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        scraper:
          - ibbi.gov.py
          - albion_bank.py
          - bank_e_auctions.py
          - web3_scrape.py

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Clean working directory
        run: |
          git clean -fdx
          git reset --hard

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Chrome and Chromedriver
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
          if [ -f /usr/bin/chromedriver ]; then
            sudo rm /usr/bin/chromedriver
          fi
          sudo ln -s /usr/lib/chromium-browser/chromedriver /usr/bin/chromedriver

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-scraping.txt

      - name: Run scraper ${{ matrix.scraper }}
        run: python ${{ matrix.scraper }}

  combine-and-alert:
    needs: run-scrapers
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Clean working directory
        run: |
          git clean -fdx
          git reset --hard

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-scraping.txt

      - name: Debug directory contents after scraping
        run: |
          ls -la auction_exports/
          find auction_exports/ -type f

      - name: Process and combine auction data
        run: python process_and_combine.py

      - name: Debug directory contents after processing
        run: |
          ls -la auction_exports/
          find auction_exports/ -type f

      - name: Send email alert
        run: python email_alert.py
        env:
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          SENDER_EMAIL: ${{ secrets.SENDER_EMAIL }}
          RECIPIENT_EMAILS: ${{ secrets.RECIPIENT_EMAILS }}

      - name: Clean temporary files
        run: |
          # Remove temporary Chrome files and other untracked files, ignoring permission errors
          find auction_exports/ -name "*.com.google.Chrome.*" -delete 2>/dev/null || true
          find auction_exports/ -name "*.crdownload" -delete 2>/dev/null || true
          find /tmp -name "chrome_user_data_*" -type d -exec rm -rf {} \; 2>/dev/null || true

      - name: Debug untracked or modified files
        run: |
          git status
          git diff

      - name: Commit and push files
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          git add --all
          git commit -m "Update auction files and scripts for $(date +%Y-%m-%d)" || echo "No changes to commit"
          git fetch origin
          git pull --rebase origin main
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
